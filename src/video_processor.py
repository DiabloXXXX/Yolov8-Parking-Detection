"""
Video processing module for vehicle detection
Handles video input, area selection, and processing modes
"""

import cv2
import numpy as np
import os
import time
from typing import List, Tuple, Optional, Dict
from pathlib import Path

class VideoProcessor:
    """Video processing class for vehicle detection"""
    
    def __init__(self, detector, config):
        """Initialize video processor"""
        self.detector = detector
        self.config = config
        self.area_points = []
        self.current_video_path = None
        self.video_info = {}
        
    def select_video(self, video_path: Optional[str] = None) -> str:
        """Select video file for processing"""
        if video_path and os.path.exists(video_path):
            self.current_video_path = video_path
            print(f"‚úÖ Video selected: {video_path}")
            return video_path
        
        # Show video selection menu
        print("üìÅ Available videos:")
        valid_videos = []
        
        for i, video in enumerate(self.config.VIDEO_PATHS, 1):
            if os.path.exists(video):
                valid_videos.append(video)
                print(f"{i}. {video}")
            else:
                print(f"{i}. {video} (‚ùå not found)")
        
        if not valid_videos:
            raise Exception("‚ùå No valid video files found!")
        
        # Get user selection
        while True:
            try:
                choice = input(f"üé¨ Select video (1-{len(self.config.VIDEO_PATHS)}): ")
                video_index = int(choice) - 1
                
                if 0 <= video_index < len(self.config.VIDEO_PATHS):
                    selected_video = self.config.VIDEO_PATHS[video_index]
                    if os.path.exists(selected_video):
                        self.current_video_path = selected_video
                        print(f"‚úÖ Video selected: {selected_video}")
                        return selected_video
                    else:
                        print("‚ùå Selected video file not found!")
                else:
                    print("‚ùå Invalid selection!")
            except (ValueError, KeyboardInterrupt):
                # Use default video
                default_video = valid_videos[0]
                self.current_video_path = default_video
                print(f"‚ö†Ô∏è Using default video: {default_video}")
                return default_video
    
    def validate_video(self, video_path: str) -> bool:
        """Validate video file and get information"""
        cap = cv2.VideoCapture(video_path)
        
        if not cap.isOpened():
            print(f"‚ùå Cannot open video: {video_path}")
            return False
        
        # Get video properties
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        duration = total_frames / fps if fps > 0 else 0
        
        cap.release()
        
        # Validate resolution
        if width < self.config.MIN_WIDTH or height < self.config.MIN_HEIGHT:
            print(f"‚ö†Ô∏è Video resolution ({width}x{height}) below minimum ({self.config.MIN_WIDTH}x{self.config.MIN_HEIGHT})")
            return False
        
        # Store video info
        self.video_info = {
            'width': width,
            'height': height,
            'fps': fps,
            'total_frames': total_frames,
            'duration': duration,
            'path': video_path
        }
        
        print(f"‚úÖ Video validated: {width}x{height}, {fps:.1f} FPS, {duration:.1f}s")
        return True
    
    def select_detection_area(self, video_path: str) -> List[Tuple[int, int]]:
        """Interactive area selection for vehicle detection"""
        cap = cv2.VideoCapture(video_path)
        
        if not cap.isOpened():
            raise Exception(f"Cannot open video: {video_path}")
        
        # Read first frame
        ret, frame = cap.read()
        cap.release()
        
        if not ret:
            raise Exception("Cannot read first frame")
        
        print("üñ±Ô∏è Click 4 points to define parking area (ESC to use default)")
        
        points = []
        window_name = f"Select Parking Area - {os.path.basename(video_path)}"
        
        def mouse_callback(event, x, y, flags, param):
            nonlocal points
            if event == cv2.EVENT_LBUTTONDOWN and len(points) < 4:
                points.append((x, y))
                print(f"   Point {len(points)}: ({x}, {y})")
        
        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
        
        # Set fullscreen if configured
        if hasattr(self.config, 'FULLSCREEN_MODE') and self.config.FULLSCREEN_MODE:
            cv2.setWindowProperty(window_name, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)
        
        cv2.setMouseCallback(window_name, mouse_callback)
        
        while True:
            display_frame = frame.copy()
            
            # Draw existing points
            for i, pt in enumerate(points):
                cv2.circle(display_frame, pt, 8, (0, 255, 0), -1)
                cv2.putText(display_frame, str(i+1), (pt[0]+10, pt[1]-10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # Draw polygon if we have enough points
            if len(points) >= 3:
                cv2.polylines(display_frame, [np.array(points)], 
                             len(points) == 4, (255, 0, 0), 3)
            
            # Add instructions
            cv2.putText(display_frame, f"Points: {len(points)}/4", (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)
            cv2.putText(display_frame, "ESC=Default, ENTER=Done", (10, 70), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            
            cv2.imshow(window_name, display_frame)
            
            key = cv2.waitKey(1) & 0xFF
            if key == 27:  # ESC
                print("‚ö†Ô∏è Using default area points")
                points = self._get_default_points(video_path)
                break
            elif key == 13 or len(points) == 4:  # ENTER or 4 points
                if len(points) == 4:
                    break
        
        cv2.destroyAllWindows()
        
        if len(points) != 4:
            print("‚ö†Ô∏è Using default area points")
            points = self._get_default_points(video_path)
        
        self.area_points = points
        print(f"üü¢ Detection area selected: {points}")
        return points
    
    def _get_default_points(self, video_path: str) -> List[Tuple[int, int]]:
        """Get default detection points for video (Full screen by default)"""
        video_name = os.path.basename(video_path)
        
        # Get actual video dimensions for full screen detection
        if hasattr(self, 'video_info') and self.video_info:
            width = self.video_info['width']
            height = self.video_info['height']
        else:
            # Fallback: get video dimensions
            cap = cv2.VideoCapture(video_path)
            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            cap.release()
        
        # Create full screen area using actual video dimensions
        default_fullscreen = [(0, 0), (width, 0), (width, height), (0, height)]
        
        # Use config points if available, otherwise use full screen
        configured_points = self.config.DEFAULT_TEST_POINTS.get(video_name, default_fullscreen)
        
        # If configured points are the generic 1920x1080, use actual video dimensions
        if configured_points == [(0, 0), (1920, 0), (1920, 1080), (0, 1080)]:
            configured_points = default_fullscreen
            
        print(f"üî≤ Using detection area: Full screen ({width}x{height})")
        return configured_points
    
    def process_video_realtime(self, video_path: str, area_points: list):
        """Process video with real-time statistics"""
        cap = cv2.VideoCapture(video_path)
        
        if not cap.isOpened():
            print(f"‚ùå Cannot open video: {video_path}")
            return
        
        print(f"üé¨ Processing video: {video_path}")
        print("Press 'q' to quit, 'p' to pause")
        
        paused = False
        video_writer = None # Initialize video_writer to None

        frame_count = 0 # Initialize frame_count here
        
        while True:
            if not paused:
                ret, frame = cap.read()
                if not ret:
                    break
                
                frame_count += 1
                
                # Skip frames for efficiency
                if frame_count % self.config.FRAME_SKIP != 0:
                    continue
                
                # Resize frame
                frame_resized = cv2.resize(frame, 
                                         (self.config.RESIZE_WIDTH, 
                                          self.config.RESIZE_HEIGHT))
                
                # Scale area points
                scale_x = self.config.RESIZE_WIDTH / self.video_info['width']
                scale_y = self.config.RESIZE_HEIGHT / self.video_info['height']
                
                scaled_points = [(int(x * scale_x), int(y * scale_y)) 
                               for x, y in area_points]
                
                # Detect vehicles with tracking
                if hasattr(self.detector, 'tracker') and self.config.TRACKING_ENABLED:
                    parked_count, moving_count, detections = self.detector.detect_vehicles_with_tracking(
                        frame_resized, scaled_points)
                else:
                    # Fallback ke deteksi tanpa tracking
                    vehicle_count, detections = self.detector.detect_vehicles(
                        frame_resized, scaled_points)
                    parked_count = vehicle_count
                    moving_count = 0
                
                # Draw results
                result_frame = self.detector.draw_detections(
                    frame_resized, detections, scaled_points)
                
                # Setup window for fullscreen if configured
                window_name = "Video Processing" # Define window_name here
                if hasattr(self.config, 'FULLSCREEN_MODE') and self.config.FULLSCREEN_MODE:
                    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
                    cv2.setWindowProperty(window_name, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)
                
                cv2.imshow(window_name, result_frame)

                # Initialize video writer after first frame is processed
                if self.config.SAVE_RESULTS and video_writer is None:
                    output_filename = f"output_{os.path.basename(video_path).split('.')[0]}_{int(time.time())}.avi"
                    output_path = Path(self.config.OUTPUT_DIR) / output_filename
                    os.makedirs(self.config.OUTPUT_DIR, exist_ok=True) # Ensure output directory exists

                    fourcc = cv2.VideoWriter_fourcc(*'DIVX') # Codec for .avi (often more compatible)
                    fps = cap.get(cv2.CAP_PROP_FPS)
                    # Use configured frame dimensions for writer
                    height, width = self.config.RESIZE_HEIGHT, self.config.RESIZE_WIDTH
                    
                    print(f"Attempting to save video to: {output_path} with dimensions {width}x{height} and FPS {fps}")
                    try:
                        video_writer = cv2.VideoWriter(str(output_path), fourcc, fps, (width, height))
                        if not video_writer.isOpened():
                            print(f"‚ö†Ô∏è Warning: Could not open video writer for {output_path}. Check codec and path. Results will not be saved.")
                            video_writer = None
                        else:
                            print(f"üíæ Saving processed video to: {output_path}")
                    except Exception as e:
                        print(f"‚ùå Error initializing video writer: {e}. Results will not be saved.")
                        video_writer = None

                # Write frame to video writer
                if video_writer:
                    video_writer.write(result_frame)
                    # print(f"Writing frame to video writer: {frame_count}") # Debug print
            
            # Handle keyboard input
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            elif key == ord('p'):
                paused = not paused
                print("‚è∏Ô∏è Paused" if paused else "‚ñ∂Ô∏è Resumed")
        
        cap.release()
        if video_writer:
            video_writer.release()
            print("Video writer released.") # Debug print
        cv2.destroyAllWindows()
        print("‚úÖ Video processing completed")
    
    def run_interactive_mode(self, video_path: Optional[str] = None) -> None:
        """Run interactive detection mode"""
        print("üöÄ INTERACTIVE VEHICLE DETECTION MODE")
        print("=" * 50)
        
        # Select video
        selected_video = self.select_video(video_path)
        
        # Validate video
        if not self.validate_video(selected_video):
            return
        
        # Select detection area
        area_points = self.select_detection_area(selected_video)
        
        # Process video in real-time
        self.process_video_realtime(selected_video, area_points)
    
    def run_auto_mode(self) -> None:
        """Run automatic detection on all videos with default settings"""
        print("ü§ñ AUTOMATIC DETECTION MODE")
        print("=" * 50)
        
        for video_path in self.config.VIDEO_PATHS:
            if not os.path.exists(video_path):
                print(f"‚ö†Ô∏è Skipping missing video: {video_path}")
                continue
            
            print(f"üìπ Processing: {os.path.basename(video_path)}")
            
            if not self.validate_video(video_path):
                continue
            
            # Use default points
            area_points = self._get_default_points(video_path)
            
            # Process video
            self.process_video_realtime(video_path, area_points)
    
    def run_test_mode(self) -> None:
        """Run comprehensive testing mode"""
        print("üß™ TESTING MODE")
        print("=" * 50)
        
        # Import tester from tools directory
        import sys
        import importlib.util
        from pathlib import Path
        
        try:
            tools_dir = Path(__file__).parent.parent / "tools"
            sys.path.insert(0, str(tools_dir))
            
            # Load tester module dynamically
            spec = importlib.util.spec_from_file_location("tester", tools_dir / "tester.py")
            if spec and spec.loader:
                tester_module = importlib.util.module_from_spec(spec)
                spec.loader.exec_module(tester_module)
                VehicleDetectionTester = tester_module.VehicleDetectionTester
                
                tester = VehicleDetectionTester(self.detector, self.config)
                tester.run_comprehensive_testing()
            else:
                print("‚ùå Could not load tester module")
                print("üí° Running basic test mode instead...")
                # Fallback to basic test
                selected_video = self.select_video(None)
                if self.validate_video(selected_video):
                    area_points = self.select_detection_area(selected_video)
                    self.process_video_realtime(selected_video, area_points)
        except Exception as e:
            print(f"‚ùå Tester module error: {e}")
            print("üí° Running basic test mode instead...")
            # Fallback to basic test
            selected_video = self.select_video(None)
            if self.validate_video(selected_video):
                area_points = self.select_detection_area(selected_video)
                self.process_video(selected_video, area_points)
